import json
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms, datasets, models
from tqdm import tqdm
from model import resnet18  # Assuming you have a custom model defined in model.py
import matplotlib.pyplot as plt
from torchvision import models
from sklearn.metrics import confusion_matrix
import numpy as np
import seaborn as sns


def plot_confusion_matrix(y_true, y_pred, classes, save_path):
    plt.rcParams["font.family"] = "Times New Roman"
    # Compute the confusion matrix and normalize it
    cm = confusion_matrix(y_true, y_pred)
    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # Normalize the confusion matrix
    cm = np.round(cm, 2)  # Round to 2 decimal places

    # Create an annotation matrix with only diagonal values
    annot = np.full(cm.shape, '', dtype=object)  # Start with an empty matrix
    np.fill_diagonal(annot, [f'{val:.2f}' for val in np.diag(cm)])  # Fill diagonal with formatted values

    # Create numeric labels for x and y axes
    numeric_labels = [str(i) for i in range(len(classes))]

    # Plotting the confusion matrix with the customized annotations
    plt.figure(figsize=(12, 10), dpi=800)
    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', xticklabels=numeric_labels, yticklabels=numeric_labels,
                linewidths=0.5, linecolor='gray', annot_kws={"size": 13})  # Add gray gridlines
    plt.xlabel('Predicted Label', fontsize=18)
    plt.ylabel('True Label', fontsize=18)
    plt.title('ResNet Normalized Confusion Matrix', fontsize=18)
    plt.savefig(save_path)
    plt.close()


def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("using {} device.".format(device))

    data_transform = {
        "train": transforms.Compose([
                                    transforms.Resize(256),
                                    transforms.CenterCrop(224),
                                    transforms.ToTensor(),
                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),
        "val": transforms.Compose([transforms.Resize(256),
                                   transforms.CenterCrop(224),
                                   transforms.ToTensor(),
                                   transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}

    train_dataset = datasets.ImageFolder(root=".../train",
                                         transform=data_transform["train"])

    bird_list = train_dataset.class_to_idx
    cla_dict = dict((val, key) for key, val in bird_list.items())
    # write dict into json file
    json_str = json.dumps(cla_dict, indent=4)
    with open('class_indices.json', 'w') as json_file:
        json_file.write(json_str)

    batch_size = 128
    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers
    print('Using {} dataloader workers every process'.format(nw))

    train_loader = torch.utils.data.DataLoader(train_dataset,
                                               batch_size=batch_size, shuffle=True,
                                               num_workers=nw)

    validate_dataset = datasets.ImageFolder(root=".../val",
                                            transform=data_transform["val"])
    valdata_loader = torch.utils.data.DataLoader(validate_dataset,
                                                 batch_size=batch_size, shuffle=False,
                                                 num_workers=nw)

    net = models.resnet18(pretrained=True)  # Load a pretrained ResNet-18 model = resnet18()
    in_channel = net.fc.in_features
    net.fc = nn.Linear(in_channel, 4)
    net.to(device)

    loss_function = nn.CrossEntropyLoss().to(device)
    optimizer = optim.AdamW(net.parameters(), lr=1e-3)
    epochs = 30
    num_classes = 4
    val_accuracy_list = []
    train_accuracy_list = []
    epochs_list = []
    train_loss_list = []
    val_loss_list = []
    val_precision_list = []
    val_recall_list = []
    val_f1_list = []

    val_all_preds = []
    val_all_labels = []

    for epoch in range(epochs):

        tp_val = {i: 0 for i in range(num_classes)}
        fp_val = {i: 0 for i in range(num_classes)}
        fn_val = {i: 0 for i in range(num_classes)}

        val_acc = 0.0  # Accumulate the number of correct predictions in the validation set
        train_acc = 0.0  # Accumulate the number of correct predictions in the training set
        val_loss = 0.0  # Accumulate the loss in the validation set
        train_loss = 0.0  # Accumulate the loss in the training set
        train_total = 0
        val_total = 0

        # Training loop
        net.train()
        train_bar = tqdm(train_loader)
        for step, (images, labels) in enumerate(train_bar):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            logits = net(images)
            loss = loss_function(logits, labels)
            loss.backward()
            optimizer.step()
            pri_lab = logits.argmax(-1)
            train_acc += (pri_lab == labels).sum().item()
            train_total += labels.size(0)
            train_loss += loss.item()
            train_bar.desc = "Train Epoch [{}/{}] Train Loss: {:.4f} Train Acc :{:.4f} " \
                .format(epoch + 1, epochs, loss.item(), train_acc / train_total)

        # Validation loop
        net.eval()
        with torch.no_grad():
            val_bar = tqdm(valdata_loader)

            for (val_images, val_labels) in val_bar:
                val_images, val_labels = val_images.to(device), val_labels.to(device)
                val_outputs = net(val_images)
                loss = loss_function(val_outputs, val_labels)
                val_loss += loss.item()
                pri_lab = val_outputs.argmax(-1)
                val_acc += (pri_lab == val_labels).sum().item()
                val_total += val_labels.size(0)
                val_bar.desc = "Val Epoch [{}/{}] Val Loss: {:.4f} Val Acc :{:.4f} " \
                    .format(epoch + 1, epochs, loss.item(), val_acc / val_total)
                for i in range(num_classes):
                    tp_val[i] += ((val_outputs.argmax(1) == i) & (val_labels == i)).sum().item()
                    fp_val[i] += ((val_outputs.argmax(1) == i) & (val_labels != i)).sum().item()
                    fn_val[i] += ((val_outputs.argmax(1) != i) & (val_labels == i)).sum().item()
                # Calculate precision, recall, and F1 score for validation
                precision_val = {i: tp_val[i] / (tp_val[i] + fp_val[i] + 1e-8) for i in range(num_classes)}
                recall_val = {i: tp_val[i] / (tp_val[i] + fn_val[i] + 1e-8) for i in range(num_classes)}
                F1_val = {i: 2 * (precision_val[i] * recall_val[i]) / (precision_val[i] + recall_val[i] + 1e-8) for i in
                          range(num_classes)}
                print(
                    "Epoch [{}/{}], Validation Precision: {:.4f}, Validation Recall: {:.4f}, Validation F1 Score: {:.4f}"
                    .format(epoch + 1, epochs,
                            sum(precision_val.values()) / num_classes,
                            sum(recall_val.values()) / num_classes,
                            sum(F1_val.values()) / num_classes))
                # Store predictions and labels for confusion matrix
                val_all_preds.extend(pri_lab.cpu().numpy())
                val_all_labels.extend(val_labels.cpu().numpy())

        # Record training and validation accuracy and loss
        val_accuracy_list.append((val_acc+1e-8) / val_total)
        train_accuracy_list.append((train_acc +1e-8) / train_total)
        train_loss_list.append((train_loss+1e-8) / len(train_loader))
        val_loss_list.append((val_loss+1e-8) / len(valdata_loader))
        val_precision_list.append(sum(precision_val.values()) / num_classes)
        val_recall_list.append(sum(recall_val.values()) / num_classes)
        val_f1_list.append(sum(F1_val.values()) / num_classes)

        epochs_list.append(epoch + 1)
        #torch.save(net.state_dict(), save_path)  # Save the model


        # Plot train and validation accuracy
        plt.figure()
        plt.plot(epochs_list, val_accuracy_list, color="red", label="val_acc")
        plt.plot(epochs_list, train_accuracy_list, color="green", label="train_acc")
        plt.xlabel("epochs")
        plt.ylabel("Acc")
        plt.title('ResNet18 in wav')
        plt.xticks([i for i in range(0, len(epochs_list), 5)])
        acc_gap = [i * 0.2 for i in range(0, min(int(len(epochs_list) / 2 + 1), 6))]
        acc_gap.append(max(val_accuracy_list))
        acc_gap.append(max(train_accuracy_list))
        plt.yticks(acc_gap)
        plt.grid()
        plt.legend()
        plt.savefig(".jpg")


        # Plot train and validation loss
        plt.figure()
        plt.plot(epochs_list, val_loss_list, color="red", label="val_loss")
        plt.plot(epochs_list, train_loss_list, color="green", label="train_loss")
        plt.xlabel("epochs")
        plt.ylabel("Loss")
        plt.title('ResNet18 in wav')
        plt.xticks([i for i in range(0, len(epochs_list), 5)])
        loss_gap = [i for i in range(0, min(int(len(epochs_list) / 2 + 1), 6))]
        loss_gap.append(max(val_loss_list))
        loss_gap.append(max(train_loss_list))
        plt.yticks(loss_gap)
        plt.grid()
        plt.legend()
        plt.savefig(".jpg")


    cm = confusion_matrix(val_all_labels, val_all_preds)
    plot_confusion_matrix(val_all_labels, val_all_preds, classes=cla_dict.values(), save_path="confusion_matrix.png")


if __name__ == '__main__':
    main()
